---
name: CI pipeline

on:
  workflow_dispatch:
    inputs:
      dataSource:
        description: Run tests for this Soda data source
        type: choice
        default: all
        options:
          - all
          - athena
          - bigquery
          - databricks
          - duckdb
          - fabric
          - postgres
          - redshift
          - snowflake
          - sqlserver
          - synapse
          - sparkdf
          - trino-postgres
          - trino-s3
  push:
    branches:
      - 'main'
    tags:
      - "*"
  pull_request:

env:
  PROJECT_NAME: soda-core

jobs:
  check:
    name: pre-commit & lockfile
    runs-on: ubuntu-24.04
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Set up UV
        uses: astral-sh/setup-uv@e58605a9b6da7c637471fab8847a5e5a6b8df081  # v5
      - name: Check lockfile is up-to-date
        run: uv lock --check
      - name: Run pre-commit
        uses: pre-commit/action@v3.0.1
  define-test-matrix:
    runs-on: ubuntu-24.04
    needs: [check]
    outputs:
      modules: ${{ steps.modules.outputs.modules }}
    steps:
      - uses: actions/checkout@v4
      - name: Set data source (workflow_dispatch)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: |
          if [ -z "${{ inputs.dataSource }}" ] || [ "${{ inputs.dataSource }}" = "all" ]; then
            echo "DATA_SOURCE=all" >> "${GITHUB_ENV}"
          else
            echo "DATA_SOURCE=${{ inputs.dataSource }}" >> "${GITHUB_ENV}"
          fi
      - name: Set data source (push)
        if: ${{ github.event_name != 'workflow_dispatch' }}
        run: |
          echo "DATA_SOURCE=all" >> "${GITHUB_ENV}"
      - name: Define modules
        id: modules
        run: |
          echo "INFO: DATA_SOURCE is set to ${DATA_SOURCE}"
          if [ "${DATA_SOURCE}" = "all" ]; then
            echo modules=$(bash scripts/test_matrix.sh) >> "$GITHUB_OUTPUT"
          else
            echo 'modules=["__DATA_SOURCE__"]' | sed "s|__DATA_SOURCE__|${DATA_SOURCE}|g" >> "$GITHUB_OUTPUT"
          fi
  test:
    runs-on: ubuntu-24.04
    needs: [define-test-matrix]
    services:
      postgres:
        # please keep the postgres version in sync with the one in docker-compose.yml for postgres
        image: ${{ ( matrix.module == 'postgres' ) && 'postgres:15.10-alpine3.21' || startsWith(matrix.module, 'trino') && 'postgres:15.10-alpine3.21' || '' }}
        env:
          POSTGRES_USER: soda_test
          POSTGRES_DB: soda_test
          POSTGRES_HOST_AUTH_METHOD: trust
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          --health-start-period 10s
        ports:
          - 5432:5432
      # trino:
      #   image: ${{ ( matrix.module == 'trino' ) && 'trinodb/trino:latest' || '' }}
      #   ports:
      #     - 8443:8443
      sqlserver:
        image: ${{ ( matrix.module == 'sqlserver' ) && 'mcr.microsoft.com/mssql/server:2022-latest' || '' }}
        env:
          ACCEPT_EULA: Y
          SA_PASSWORD: Password1!
        ports:
          - 1433:1433
        options: >-
          --health-cmd "/opt/mssql-tools18/bin/sqlcmd -S localhost -U sa -P Password1! -Q 'select 1' -C -b -o /dev/null"
          --health-interval 1s
          --health-timeout 2s
          --health-retries 10
          --health-start-period 10s
    strategy:
      fail-fast: false
      matrix:
        python-version:
          - "3.10"
          - "3.11"
          - "3.12"
        module: ${{ fromJSON(needs.define-test-matrix.outputs.modules) }}
    env:
      SNOWFLAKE_ACCOUNT: ${{ vars.SNOWFLAKE_CI_ACCOUNT }}
      SNOWFLAKE_USER: ${{ vars.SNOWFLAKE_CI_USERNAME }}
      SNOWFLAKE_DATABASE: ${{ vars.SNOWFLAKE_CI_DATABASE }}
      DATABRICKS_HOST: ${{ vars.DATABRICKS_CI_HOST }}
      DATABRICKS_HTTP_PATH: ${{ vars.DATABRICKS_CI_HTTP_PATH }}
      DATABRICKS_CATALOG: ${{ vars.DATABRICKS_CI_CATALOG }}
      REDSHIFT_HOST: ${{ vars.REDSHIFT_CI_HOST }}
      REDSHIFT_USERNAME: ${{ vars.REDSHIFT_CI_USERNAME }}
      REDSHIFT_DATABASE: "soda_test"
      REDSHIFT_PORT: "5439"
      ATHENA_S3_TEST_DIR: ${{ vars.ATHENA_CI_STAGING_DIR }}
      ATHENA_SCHEMA: ${{ vars.ATHENA_CI_SCHEMA }}
      ATHENA_WORKGROUP: ${{ vars.ATHENA_CI_WORKGROUP }}
      SQLSERVER_USERNAME: sa
      SQLSERVER_PASSWORD: Password1!
      SQLSERVER_DATABASE: master
      SQLSERVER_SCHEMA: dbo
      SYNAPSE_HOST: ${{ vars.MICROSOFT_SYNAPSE_CI_HOST }}
      SYNAPSE_DATABASE: sodacisynapse
      SYNAPSE_AUTHENTICATION_TYPE: activedirectoryserviceprincipal
      FABRIC_HOST: ${{ vars.MICROSOFT_FABRIC_CI_HOST }}
      FABRIC_DATABASE: soda-ci-fabric-warehouse
      FABRIC_AUTHENTICATION_TYPE: activedirectoryserviceprincipal
      SODA_CORE_TELEMETRY_LOCAL_TEST_MODE: "true"
      

    steps:
      - uses: actions/checkout@v4
      - name: Resolve module
        run: |
          MODULE="${{ matrix.module }}"
          case "$MODULE" in
            trino-postgres) echo "TEST_MODULE=trino" >> "$GITHUB_ENV"; echo "TRINO_CATALOG=db" >> "$GITHUB_ENV" ;;
            trino-s3)       echo "TEST_MODULE=trino" >> "$GITHUB_ENV"; echo "TRINO_CATALOG=iceberg" >> "$GITHUB_ENV" ;;
            *)              echo "TEST_MODULE=$MODULE" >> "$GITHUB_ENV" ;;
          esac
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Set up UV
        uses: astral-sh/setup-uv@e58605a9b6da7c637471fab8847a5e5a6b8df081  # v5

      - name: Install dependencies
        run: |
          curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -
          curl https://packages.microsoft.com/config/ubuntu/21.04/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list > /dev/null
          sudo apt-get update
          ACCEPT_EULA=Y sudo apt-get install -y libsasl2-dev msodbcsql18

      - name: Get external secrets
        uses: aws-actions/aws-secretsmanager-get-secrets@a9a7eb4e2f2871d30dc5b892576fde60a2ecc802  # v2.0.10
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_BUILD_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_BUILD_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_BUILD_DEFAULT_REGION }}
        with:
          secret-ids: |
            ,/soda/github/common/data-sources/envs
          parse-json-secrets: true

      - name: Get external secrets (special)
        uses: aws-actions/aws-secretsmanager-get-secrets@a9a7eb4e2f2871d30dc5b892576fde60a2ecc802  # v2.0.10
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_BUILD_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_BUILD_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_BUILD_DEFAULT_REGION }}
        with:
          secret-ids: |
            BIGQUERY_ACCOUNT_INFO_JSON,/soda/github/common/data-sources/BIGQUERY_ACCOUNT_INFO_JSON
      - name: Configure Trino
        if: startsWith(matrix.module, 'trino')
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_BUILD_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_BUILD_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_BUILD_DEFAULT_REGION }}
          TRINO_CI_ASSUME_ROLE_ARN: ${{ secrets.TRINO_CI_ASSUME_ROLE_ARN }}
        run: |
          set -e
          # Override env vars for the local Trino instance (remote instance requires twingate)
          echo "TRINO_HOST=localhost" >> "$GITHUB_ENV"
          echo "TRINO_PORT=8443" >> "$GITHUB_ENV"
          echo "TRINO_USERNAME=soda-test" >> "$GITHUB_ENV"
          echo "TRINO_PASSWORD=soda-test" >> "$GITHUB_ENV"
          echo "TRINO_VERIFY=false" >> "$GITHUB_ENV"

          cd soda-trino/local_instance
          ./generate_keys.sh

          # Assume role in dev account for Glue + S3 (Iceberg); use temp creds for Trino process
          if [ -n "${TRINO_CI_ASSUME_ROLE_ARN}" ]; then
            CREDS=$(aws sts assume-role --role-arn "${TRINO_CI_ASSUME_ROLE_ARN}" --role-session-name github-actions-trino-ci --output json)
            export AWS_ACCESS_KEY_ID=$(echo "$CREDS" | jq -r '.Credentials.AccessKeyId')
            export AWS_SECRET_ACCESS_KEY=$(echo "$CREDS" | jq -r '.Credentials.SecretAccessKey')
            export AWS_SESSION_TOKEN=$(echo "$CREDS" | jq -r '.Credentials.SessionToken')

            # Create Glue database for CI (idempotent)
            aws glue create-database --database-input '{"Name":"soda_ci_trino","Description":"Trino Iceberg CI"}' 2>/dev/null || true
          else
            unset AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN
          fi

          # Start Trino with our config (and AWS_* env when assumed role); no service container
          DOCKER_ENV=""
          if [ -n "${AWS_SESSION_TOKEN:-}" ]; then
            DOCKER_ENV="-e AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} -e AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} -e AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN} -e AWS_REGION=${AWS_REGION:-eu-west-1}"
          fi
          # Find the GitHub Actions job network so Trino can reach the postgres service container
          GH_NETWORK=$(docker network ls --format '{{.Name}}' | grep -E '^github_network_' | head -1)

          docker run -d --name trino-ci -p 8443:8443 $DOCKER_ENV \
            ${GH_NETWORK:+--network "$GH_NETWORK"} \
            -v "$(pwd)/trino-config:/etc/trino" \
            -v "$(pwd)/trino-catalog:/etc/trino/catalog" \
            trinodb/trino:latest

          echo "Waiting for Trino to be ready..."
          for i in $(seq 1 24); do
            if curl -k -s https://localhost:8443/v1/info > /dev/null 2>&1; then
              echo "Trino is ready"
              break
            fi
            if [ "$i" -eq 24 ]; then
              echo "ERROR: Trino failed to start within 2 minutes"
              docker logs trino-ci
              exit 1
            fi
            sleep 5
          done

          # Verify a catalog query works end-to-end
          echo "Verifying Trino catalogs..."
          if ! curl -k -s -f -u soda-test:soda-test \
            -X POST https://localhost:8443/v1/statement \
            -H 'X-Trino-User: soda-test' \
            -d 'SHOW CATALOGS' > /dev/null 2>&1; then
            echo "WARNING: Trino catalog verification failed"
            docker logs trino-ci
          fi
      - name: Dump Trino logs
        if: failure() && startsWith(matrix.module, 'trino')
        run: docker logs trino-ci
      - name: Run tests
        run: |
          uv sync --locked --all-packages --group dev

          if [ "${{ matrix.module }}" = "sparkdf" ]; then
            sudo apt-get update
            sudo apt-get install -y openjdk-17-jdk
            export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
            export PATH=$JAVA_HOME/bin:$PATH
            echo "JAVA_HOME=$JAVA_HOME" >> "$GITHUB_ENV"
            echo "PATH=$PATH" >> "$GITHUB_ENV"
          fi

          export TEST_DATASOURCE=${{ env.TEST_MODULE }}
          uv run python -m pytest -ra soda-tests/tests/integration
          if [ "${{ env.TEST_MODULE }}" = "postgres" ]; then
            uv run python -m pytest -ra soda-tests/tests/unit
            uv run python -m pytest -ra soda-tests/tests/feature
          fi
          uv run python -m pytest -ra soda-${{ env.TEST_MODULE }}/tests

          if [ "${{ env.TEST_MODULE }}" = "databricks" ]; then
            export DATABRICKS_CATALOG=hive_metastore
            echo "Changed DATABRICKS_CATALOG environment variable to hive_metastore"
            uv run python -m pytest -ra soda-tests/tests/integration
          fi

  define-matrix:
    if: github.ref_name == 'main' || contains(github.ref, 'refs/tags/')
    runs-on: ubuntu-24.04
    needs: [test]
    outputs:
      modules: ${{ steps.modules.outputs.modules }}
    steps:
      - uses: actions/checkout@v4
      - name: Define modules
        id: modules
        run: |
          echo modules=$(bash scripts/release_matrix.sh) >> "$GITHUB_OUTPUT"
  release-to-dev-pypi:
    if: github.ref_name == 'main' # Pushes to "main" branch
    runs-on: ubuntu-24.04
    needs: [define-matrix]
    strategy:
      fail-fast: false
      matrix:
        module: ${{ fromJSON(needs.define-matrix.outputs.modules) }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Set up UV
        uses: astral-sh/setup-uv@e58605a9b6da7c637471fab8847a5e5a6b8df081  # v5
      - name: Debug GITHUB_REF
        run: echo "GITHUB_REF=$GITHUB_REF"
      - name: Release ${{ matrix.module }}
        run: |
          uv venv .venv
          source .venv/bin/activate
          uv pip install tbump build twine

          if [ "${GITHUB_REF#refs/tags/}" != "$GITHUB_REF" ]; then
            VERSION="${GITHUB_REF#refs/tags/}"
            echo "Using tag version: $VERSION"
          else
            CURRENT_VERSION_ROOT="$(tbump current-version | sed -E 's/((a|b|rc)[0-9]+|\.dev[0-9]+)$//')"
            echo "No tag found, bumping to dev version: $CURRENT_VERSION_ROOT"
            tbump --only-patch --non-interactive ${CURRENT_VERSION_ROOT}.dev${GITHUB_RUN_NUMBER}
          fi

          cd ${{ matrix.module }}
          python3 -m build
      # Stagger uploads so many packages don't hit PyPI at once (reduces 503s)
      - name: Stagger uploads
        run: |
          DELAY=$(echo -n "${{ matrix.module }}" | cksum | awk '{print $1 % 91}')
          echo "Staggering upload by ${DELAY}s..."
          sleep $DELAY
      - name: Publish package to pypi
        uses: pypa/gh-action-pypi-publish@ed0c53931b1dc9bd32cbe73a98c7f6766f8a527e  # v1.13.0
        with:
          packages-dir: ${{ matrix.module }}/dist
          user: ${{ secrets.DEV_PYPI_USERNAME }}
          password: ${{ secrets.DEV_PYPI_PASSWORD }}
          repository-url: ${{ secrets.DEV_PYPI_URL }}
  release-to-pypi:
    if: startsWith(github.ref, 'refs/tags/')  # When tagged
    runs-on: ubuntu-24.04
    needs: [define-matrix]
    strategy:
      fail-fast: false
      matrix:
        module: ${{ fromJSON(needs.define-matrix.outputs.modules) }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Set up UV
        uses: astral-sh/setup-uv@e58605a9b6da7c637471fab8847a5e5a6b8df081  # v5
      - name: Debug GITHUB_REF
        run: echo "GITHUB_REF=$GITHUB_REF"
      - name: Get external secrets
        uses: aws-actions/aws-secretsmanager-get-secrets@a9a7eb4e2f2871d30dc5b892576fde60a2ecc802  # v2.0.10
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_BUILD_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_BUILD_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_BUILD_DEFAULT_REGION }}
        with:
          secret-ids: |
            PYPI_USERNAME,/soda/github/common/SODA_PYPI_CLOUD_WRITE_USERNAME
            PYPI_PASSWORD,/soda/github/common/SODA_PYPI_CLOUD_WRITE_PASSWORD
      - name: Release ${{ matrix.module }}
        run: |
          uv venv .venv
          source .venv/bin/activate
          uv pip install tbump build twine

          RELEASE_VERSION="$(echo ${GITHUB_REF_NAME} | sed -E 's/v(.*)/\1/')"
          tbump --only-patch --non-interactive ${RELEASE_VERSION}
          echo "Using tag version: ${RELEASE_VERSION}"

          cd ${{ matrix.module }}
          python3 -m build
      # Stagger uploads so many packages don't hit PyPI at once (reduces 503s)
      - name: Stagger uploads
        run: |
          DELAY=$(echo -n "${{ matrix.module }}" | cksum | awk '{print $1 % 91}')
          echo "Staggering upload by ${DELAY}s..."
          sleep $DELAY
      - name: Publish package to Soda PyPI
        uses: pypa/gh-action-pypi-publish@ed0c53931b1dc9bd32cbe73a98c7f6766f8a527e  # v1.13.0
        with:
          packages-dir: ${{ matrix.module }}/dist
          user: ${{ env.PYPI_USERNAME }}
          password: ${{ env.PYPI_PASSWORD }}
          repository-url: ${{ vars.CLOUD_PYPI_REPOSITORY }}
      - name: Publish package to public PyPI
        uses: pypa/gh-action-pypi-publish@ed0c53931b1dc9bd32cbe73a98c7f6766f8a527e  # v1.13.0
        with:
          packages-dir: ${{ matrix.module }}/dist
          user: __token__
          password: ${{ secrets.PYPI_API_TOKEN }}
